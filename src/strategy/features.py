# quant_v2/src/strategy/features.py
import numpy as np
import pandas as pd
from src import config

def add_technical_features(df):
    """
    Generates Phase 3 features: VWAP Dist, Volatility, Vol Impact.
    Uses pure pandas (no external TA lib) for robustness.
    """
    # Create copy to avoid SettingWithCopy warnings
    df = df.copy()

    # --- 1. VWAP Calculation (Intraday) ---
    # Reset VWAP at the start of each day
    df['typical_price'] = (df['high'] + df['low'] + df['close']) / 3
    df['pv'] = df['typical_price'] * df['volume']
    
    # Group by date to reset cumulative sums daily
    daily_groups = df.groupby(df.index.date)
    df['cum_pv'] = daily_groups['pv'].cumsum()
    df['cum_vol'] = daily_groups['volume'].cumsum()
    df['vwap'] = df['cum_pv'] / df['cum_vol']
    
    # Feature: Distance from VWAP (Log-diff for stationarity)
    df['feat_dist_vwap'] = np.log(df['close'] / df['vwap'])

    # --- 2. Volatility (Rolling Std Dev) ---
    # Log-returns for normalization
    df['log_ret'] = np.log(df['close'] / df['close'].shift(1))
    df['feat_vol_15m'] = df['log_ret'].rolling(window=15).std()

    # --- 3. Volume Impact (OFI Proxy) ---
    # Measures if volume is pushing price up or down.
    # Normalized by recent average volume to handle open/close spikes.
    df['vol_ma_20'] = df['volume'].rolling(window=20).mean()
    # Avoid division by zero
    df['vol_ma_20'] = df['vol_ma_20'].replace(0, np.nan) 
    df['feat_vol_impact'] = (df['volume'] / df['vol_ma_20']) * (df['close'] - df['open'])

    # --- 4. RSI (Momentum) - Pure Pandas ---
    # Using Wilder's Smoothing (alpha = 1/14)
    delta = df['close'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    
    # EWM with alpha=1/14 mimics Wilder's Smoothing
    avg_gain = gain.ewm(alpha=1/14, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/14, adjust=False).mean()
    
    rs = avg_gain / avg_loss
    df['feat_rsi_14'] = 100 - (100 / (1 + rs))

    # --- 5. Liquidity/Spread Proxy ---
    # (High - Low) / Close
    df['feat_spread_proxy'] = (df['high'] - df['low']) / df['close']

    # --- Cleanup ---
    drop_cols = ['typical_price', 'pv', 'cum_pv', 'cum_vol', 'vol_ma_20']
    df.drop(columns=drop_cols, inplace=True, errors='ignore')

    # Drop NaN values generated by rolling windows
    return df.dropna()

def run_features_pipeline(target_symbol):
    """
    Loads processed data, adds features, and saves for Labeling.
    """
    print(f"--> Generating Features for {target_symbol}...")
    
    # Load basic processed bars (OHLCV)
    input_path = config.DATA_PROCESSED / f"{target_symbol}_1min.parquet"
    if not input_path.exists():
        print(f"  [!] Error: Input file missing {input_path}")
        return None
    
    df = pd.read_parquet(input_path)
    
    # Apply Feature Engineering
    df_features = add_technical_features(df)
    
    # Save output
    output_path = config.DATA_PROCESSED / f"{target_symbol}_features.parquet"
    df_features.to_parquet(output_path)
    print(f"  [SUCCESS] Saved Features: {output_path}")
    print(f"    Rows: {len(df_features)}")
    
    return df_features